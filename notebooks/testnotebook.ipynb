{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47f9bc35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\Users\\\\oriol\\\\GitHub_Repos\\\\CNN-classification', 'c:\\\\Users\\\\oriol\\\\GitHub_Repos\\\\CNN-classification\\\\utils', 'c:\\\\Users\\\\oriol\\\\anaconda3\\\\envs\\\\pytorch\\\\python312.zip', 'c:\\\\Users\\\\oriol\\\\anaconda3\\\\envs\\\\pytorch\\\\DLLs', 'c:\\\\Users\\\\oriol\\\\anaconda3\\\\envs\\\\pytorch\\\\Lib', 'c:\\\\Users\\\\oriol\\\\anaconda3\\\\envs\\\\pytorch', '', 'c:\\\\Users\\\\oriol\\\\anaconda3\\\\envs\\\\pytorch\\\\Lib\\\\site-packages', 'c:\\\\Users\\\\oriol\\\\anaconda3\\\\envs\\\\pytorch\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\oriol\\\\anaconda3\\\\envs\\\\pytorch\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\oriol\\\\anaconda3\\\\envs\\\\pytorch\\\\Lib\\\\site-packages\\\\Pythonwin']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path \n",
    "from torchvision.transforms import v2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "modulepath = Path.cwd().parent / \"utils\"\n",
    "modulepath = str(modulepath)\n",
    "projectpath = Path.cwd().parent\n",
    "projectpath = str(projectpath)\n",
    "if modulepath not in sys.path:\n",
    "    sys.path.insert(0,str(modulepath))\n",
    "if projectpath not in sys.path:\n",
    "    sys.path.insert(0,str(projectpath))  \n",
    "print(sys.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1c23cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_loaders import create_train_test_dataloaders\n",
    "transform = v2.Compose([v2.RandomCrop(size=(20, 20))])#,v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08b8a80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_basic,test_basic = create_train_test_dataloaders(\"FashionMNIST\")\n",
    "train_augmented,test_augmented = create_train_test_dataloaders(\"FashionMNIST\",transform=transform)\n",
    "img_basic,label_basic = next(iter(train_basic))\n",
    "img_augmented,label_augmented = next(iter(train_augmented))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0b33942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(-0.5), np.float64(19.5), np.float64(19.5), np.float64(-0.5))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(1,2)\n",
    "ax[0].imshow(img_basic[0].permute(1,2,0),cmap=\"gray\")\n",
    "ax[1].imshow(img_augmented[0].permute(1,2,0),cmap=\"gray\")\n",
    "ax[0].axis(False)\n",
    "ax[1].axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfe83b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 28, 28])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_basic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1b73328",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.model_architectures import TinyVGG\n",
    "from torchinfo import summary \n",
    "\n",
    "tvgg = TinyVGG(1,20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68c2326d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "TinyVGG                                  [32, 10]                  --\n",
       "├─Sequential: 1-1                        [32, 20, 12, 12]          --\n",
       "│    └─Conv2d: 2-1                       [32, 20, 26, 26]          200\n",
       "│    └─ReLU: 2-2                         [32, 20, 26, 26]          --\n",
       "│    └─Conv2d: 2-3                       [32, 20, 24, 24]          3,620\n",
       "│    └─ReLU: 2-4                         [32, 20, 24, 24]          --\n",
       "│    └─MaxPool2d: 2-5                    [32, 20, 12, 12]          --\n",
       "├─Sequential: 1-2                        [32, 20, 4, 4]            --\n",
       "│    └─Conv2d: 2-6                       [32, 20, 10, 10]          3,620\n",
       "│    └─ReLU: 2-7                         [32, 20, 10, 10]          --\n",
       "│    └─Conv2d: 2-8                       [32, 20, 8, 8]            3,620\n",
       "│    └─ReLU: 2-9                         [32, 20, 8, 8]            --\n",
       "│    └─MaxPool2d: 2-10                   [32, 20, 4, 4]            --\n",
       "├─Sequential: 1-3                        [32, 10]                  --\n",
       "│    └─Flatten: 2-11                     [32, 320]                 --\n",
       "│    └─Linear: 2-12                      [32, 10]                  3,210\n",
       "==========================================================================================\n",
       "Total params: 14,270\n",
       "Trainable params: 14,270\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 90.15\n",
       "==========================================================================================\n",
       "Input size (MB): 0.10\n",
       "Forward/backward pass size (MB): 7.25\n",
       "Params size (MB): 0.06\n",
       "Estimated Total Size (MB): 7.41\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(tvgg,input_size=[32,1,28,28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ceeec08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1114, 0.1015, 0.0978, 0.0961, 0.1002, 0.0979, 0.0974, 0.1039, 0.0959,\n",
       "         0.0980]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvgg.cpu()\n",
    "tvgg.forward(img_basic[0].unsqueeze(dim=0))\n",
    "torch.softmax(tvgg.forward(img_basic[0].unsqueeze(dim=0)),1)\n",
    "\n",
    "#next(tvgg.parameters()).is_cuda #check if model on cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402c7971",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriol\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.utils' has no attribute 'tensorboard'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrain\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_architectures\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TinyVGG\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata_loaders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_train_test_dataloaders\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\oriol\\GitHub_Repos\\CNN-classification\\utils\\train.py:100\u001b[39m\n\u001b[32m     90\u001b[39m     \u001b[38;5;66;03m#print(f\"Test loss: {test_loss:.4f} | Test acc: {100*test_acc:.0f}%\")\u001b[39;00m\n\u001b[32m     91\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m test_loss, test_acc\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain\u001b[39m(model: torch.nn.Module, \n\u001b[32m     95\u001b[39m           train_dataloader: torch.utils.data.DataLoader, \n\u001b[32m     96\u001b[39m           test_dataloader: torch.utils.data.DataLoader, \n\u001b[32m     97\u001b[39m           optimizer: torch.optim.Optimizer,\n\u001b[32m     98\u001b[39m           loss_fn: torch.nn.Module,\n\u001b[32m     99\u001b[39m           epochs: \u001b[38;5;28mint\u001b[39m, \n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m           writer: \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensorboard\u001b[49m.writer.SummaryWriter,  \u001b[38;5;66;03m#type: ignore\u001b[39;00m\n\u001b[32m    101\u001b[39m           device=device \u001b[38;5;66;03m# new parameter to take in a writer \u001b[39;00m\n\u001b[32m    102\u001b[39m           ) -> Dict[\u001b[38;5;28mstr\u001b[39m, List]:\n\u001b[32m    103\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Trains and tests a PyTorch model.\u001b[39;00m\n\u001b[32m    104\u001b[39m \n\u001b[32m    105\u001b[39m \u001b[33;03m    Passes a target PyTorch models through train_step() and test_step()\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    135\u001b[39m \u001b[33;03m                test_acc: [0.3400, 0.2973]} \u001b[39;00m\n\u001b[32m    136\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    137\u001b[39m     \u001b[38;5;66;03m# Create empty results dictionary\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: module 'torch.utils' has no attribute 'tensorboard'"
     ]
    }
   ],
   "source": [
    "from utils.train import train\n",
    "\n",
    "#First change how I import tensorboard\n",
    "\n",
    "from utils.model_architectures import TinyVGG\n",
    "from utils.data_loaders import create_train_test_dataloaders\n",
    "from utils.config import device \n",
    "from torch import nn\n",
    "train_dataloader, test_dataloader = create_train_test_dataloaders()\n",
    "\n",
    "model_0 = TinyVGG(input_shape=1,hidden_channels=10,output_shape=10).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(),lr=0.01)\n",
    "\n",
    "train(model=model_0,train_dataloader=train_dataloader,test_dataloader=test_dataloader,optimizer=optimizer,loss_fn=loss_fn,epochs=1,writer=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ba9b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
