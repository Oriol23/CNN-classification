{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b2276bd",
   "metadata": {},
   "source": [
    "# SETUP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b2721885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\Users\\\\oriol\\\\GitHub_Repos\\\\CNN-classification', 'c:\\\\Users\\\\oriol\\\\GitHub_Repos\\\\CNN-classification\\\\utils', 'c:\\\\Users\\\\oriol\\\\anaconda3\\\\envs\\\\pytorch\\\\python312.zip', 'c:\\\\Users\\\\oriol\\\\anaconda3\\\\envs\\\\pytorch\\\\DLLs', 'c:\\\\Users\\\\oriol\\\\anaconda3\\\\envs\\\\pytorch\\\\Lib', 'c:\\\\Users\\\\oriol\\\\anaconda3\\\\envs\\\\pytorch', '', 'c:\\\\Users\\\\oriol\\\\anaconda3\\\\envs\\\\pytorch\\\\Lib\\\\site-packages', 'c:\\\\Users\\\\oriol\\\\anaconda3\\\\envs\\\\pytorch\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\oriol\\\\anaconda3\\\\envs\\\\pytorch\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\oriol\\\\anaconda3\\\\envs\\\\pytorch\\\\Lib\\\\site-packages\\\\Pythonwin']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "modulepath = Path.cwd().parent / \"utils\"\n",
    "modulepath = str(modulepath)\n",
    "projectpath = Path.cwd().parent\n",
    "projectpath = str(projectpath)\n",
    "if modulepath not in sys.path:\n",
    "    sys.path.insert(0,str(modulepath))\n",
    "if projectpath not in sys.path:\n",
    "    sys.path.insert(0,str(projectpath))  \n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44888dd4",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "433b2f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Created SummaryWriter, saving to: c:\\Users\\oriol\\GitHub_Repos\\CNN-classification\\experiment_logs\\runs\\Try_categorical_HP\\TinyVGG_1\\Hidden_Channels_20_Epochs_2_lr_0.1_Iter_2_Size_0.05_Fruit_Oranges...\n",
      "Iteration 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c55d0160319745c48f12e97244e3d7ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc78447189854e9b864eaa1efbf1ece6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Created experiment metadata, saving to: c:\\Users\\oriol\\GitHub_Repos\\CNN-classification\\experiment_logs\\results\\Try_categorical_HP\\TinyVGG_1\\Hidden_Channels_20_Epochs_2_lr_0.1_Iter_2_Size_0.05_Fruit_Oranges...\n",
      "[INFO] Saving the above results to: c:\\Users\\oriol\\GitHub_Repos\\CNN-classification\\experiment_logs\\results\\Try_categorical_HP\\TinyVGG_1\\Hidden_Channels_20_Epochs_2_lr_0.1_Iter_2_Size_0.05_Fruit_Oranges\\Results.feather\n",
      "[INFO] Created SummaryWriter, saving to: c:\\Users\\oriol\\GitHub_Repos\\CNN-classification\\experiment_logs\\runs\\Try_categorical_HP\\TinyVGG_1\\Hidden_Channels_20_Epochs_2_lr_0.1_Iter_2_Size_0.05_Fruit_Apples...\n",
      "Iteration 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffea4353e4744a3f94f7bb6d73673a7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f622d81b7c5b420c98a5c2630cbbaa7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Created experiment metadata, saving to: c:\\Users\\oriol\\GitHub_Repos\\CNN-classification\\experiment_logs\\results\\Try_categorical_HP\\TinyVGG_1\\Hidden_Channels_20_Epochs_2_lr_0.1_Iter_2_Size_0.05_Fruit_Apples...\n",
      "[INFO] Saving the above results to: c:\\Users\\oriol\\GitHub_Repos\\CNN-classification\\experiment_logs\\results\\Try_categorical_HP\\TinyVGG_1\\Hidden_Channels_20_Epochs_2_lr_0.1_Iter_2_Size_0.05_Fruit_Apples\\Results.feather\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from utils.engine import train\n",
    "from utils.model_architectures import TinyVGG_1\n",
    "from utils.data_loaders import create_train_test_dataloaders\n",
    "from utils.helpers import create_writer\n",
    "from utils.helpers import create_dataframe\n",
    "from utils.helpers import hyperparameter_combinations\n",
    "from utils.helpers import save_dataframe\n",
    "from utils.helpers import create_and_save_experiment_metadata\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "#SEED = 0\n",
    "#torch.manual_seed(SEED)\n",
    "# There are other sources of randomness, so manual_seed does not enable \n",
    "# reproducibility\n",
    "\n",
    "#next(model.parameters()).is_cuda #check if model on cuda\n",
    "#from torchinfo import summary\n",
    "#summary(tvgg,input_size=[32,1,28,28])\n",
    "\n",
    "# A Hyperparameter named Iter controls the number of iterations for a given\n",
    "# set of hyperparameters\n",
    "HYPERPARAMETERS = {'Hidden_Channels': [20],\n",
    "                   'Epochs': [2],\n",
    "                   'lr': [0.1],\n",
    "                   'Iter': [2],\n",
    "                   'Size': [0.05],\n",
    "                   'Fruit': [\"Oranges\",\"Apples\"]\n",
    "                   }\n",
    "\n",
    "experiment_name = \"Try_categorical_HP\"\n",
    "hp_combinations = hyperparameter_combinations(HYPERPARAMETERS)\n",
    "hp_keys = HYPERPARAMETERS.keys()\n",
    "\n",
    "for combination in hp_combinations:\n",
    "    HIDDEN_CHANNELS = combination[\"Hidden_Channels\"]\n",
    "    NUM_EPOCHS = combination[\"Epochs\"]\n",
    "    LR = combination[\"lr\"]\n",
    "        # HIDDEN_CHANNELS, NUM_EPOCHS, LR have to be specified, cannot be none\n",
    "    ITER = combination[\"Iter\"] if \"Iter\" in hp_keys else None \n",
    "        # ITER Defaults to 1 when None\n",
    "    SIZE = combination[\"Size\"] if \"Size\" in hp_keys else None \n",
    "        # SIZE Defaults to 1.0 when None\n",
    "\n",
    "    train_dataloader, test_dataloader = create_train_test_dataloaders(size=SIZE) #type: ignore\n",
    "\n",
    "    # create multiple models and optimizers, one pair for every iteration\n",
    "    model_0 = []\n",
    "    optimizer_0 = []\n",
    "    if ITER:\n",
    "        n_iters = ITER\n",
    "    else:\n",
    "        n_iters = 1\n",
    "    for n in range(n_iters):\n",
    "        mod = TinyVGG_1(input_shape=1,hidden_channels=HIDDEN_CHANNELS,output_shape=10).to(device)\n",
    "        model_0.append(mod)\n",
    "        optimizer_0.append(torch.optim.SGD(params=mod.parameters(),lr=LR))\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    model_name = model_0[0]._get_name()\n",
    "    #model_name = \"Model_3\"\n",
    "\n",
    "    extra = \"\"\n",
    "    namelist = [str(key)+\"_\"+str(val)+\"_\" for key,val in combination.items()]\n",
    "    for elem in namelist:\n",
    "        extra += elem\n",
    "    extra = extra[:-1]\n",
    "\n",
    "    # Create a writer to save results to tensorboard\n",
    "    writer = create_writer(experiment_name=experiment_name,\n",
    "                           model_name=model_name,\n",
    "                           extra=extra)\n",
    "    # Train the model for a number of epochs and log the results to tensorboard\n",
    "    results = train(model=model_0,\n",
    "                    train_dataloader=train_dataloader,\n",
    "                    test_dataloader=test_dataloader,\n",
    "                    optimizer=optimizer_0,\n",
    "                    loss_fn=loss_fn,\n",
    "                    epochs=NUM_EPOCHS,\n",
    "                    iters=ITER,\n",
    "                    writer=writer)\n",
    "    # Store additional information on the experiment\n",
    "    create_and_save_experiment_metadata(experiment_name=experiment_name,\n",
    "                                        model_name=model_name,\n",
    "                                        extra=extra,\n",
    "                                        train_dataloader=train_dataloader,\n",
    "                                        test_dataloader=test_dataloader,\n",
    "                                        model=model_0[0],\n",
    "                                        optimizer=optimizer_0[0],\n",
    "                                        loss_fn=loss_fn,\n",
    "                                        epochs=NUM_EPOCHS,\n",
    "                                        hyperparameters_combination=combination\n",
    "                                        )\n",
    "    # Store the results of the accuracy and loss as a dataframe\n",
    "    df = create_dataframe(results=results,\n",
    "                          hyperparameters_combination=combination)\n",
    "    save_dataframe(df=df,\n",
    "                   model_name=model_name,\n",
    "                   experiment_name=experiment_name,\n",
    "                   extra=extra)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66fd541",
   "metadata": {},
   "source": [
    "# METADATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "509914f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metadata(md):\n",
    "    for key,value in zip(md.keys(),md.values()):\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de7e0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.helpers import retrieve_metadata\n",
    "\n",
    "md_t3m = retrieve_metadata(experiment_name=\"Test_3_Models\",model_name=\"TinyVGG_1\",extra=\"Hidden_Channels_30_Epochs_3_lr_0.1_Iter_2_Size_0.11\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6dcd3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date: 16-09-2025 00:32\n",
      "experiment name: Test_3_models\n",
      "model name: TinyVGG_1\n",
      "learning rate: 0.1\n",
      "epochs: 3\n",
      "loss function: CrossEntropyLoss\n",
      "optimizer name: SGD\n",
      "dataset: FashionMNIST\n",
      "training dataset size: 6600\n",
      "testing dataset size: 1100\n",
      "batch size: 32\n",
      "Hyperparams: {'Hidden_Channels': 30, 'Epochs': 3, 'lr': 0.1, 'Iter': 2, 'Size': 0.11}\n",
      "optimizer params: {'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'fused': None}\n",
      "model params: {'layer_1': Sequential(\n",
      "  (0): Conv2d(1, 30, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (3): ReLU()\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "), 'layer_2': Sequential(\n",
      "  (0): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (3): ReLU()\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "), 'layer_3': Sequential(\n",
      "  (0): Flatten(start_dim=1, end_dim=-1)\n",
      "  (1): Linear(in_features=480, out_features=10, bias=True)\n",
      ")}\n"
     ]
    }
   ],
   "source": [
    "print_metadata(md_t3m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7868fb2c",
   "metadata": {},
   "source": [
    "# Trial and error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330a1bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d544749",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
