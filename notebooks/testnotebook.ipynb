{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47f9bc35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\Users\\\\oriol\\\\GitHub_Repos\\\\CNN-classification', 'c:\\\\Users\\\\oriol\\\\GitHub_Repos\\\\CNN-classification\\\\utils', 'c:\\\\Users\\\\oriol\\\\anaconda3\\\\envs\\\\pytorch_cu126\\\\python312.zip', 'c:\\\\Users\\\\oriol\\\\anaconda3\\\\envs\\\\pytorch_cu126\\\\DLLs', 'c:\\\\Users\\\\oriol\\\\anaconda3\\\\envs\\\\pytorch_cu126\\\\Lib', 'c:\\\\Users\\\\oriol\\\\anaconda3\\\\envs\\\\pytorch_cu126', '', 'c:\\\\Users\\\\oriol\\\\anaconda3\\\\envs\\\\pytorch_cu126\\\\Lib\\\\site-packages', 'c:\\\\Users\\\\oriol\\\\anaconda3\\\\envs\\\\pytorch_cu126\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\oriol\\\\anaconda3\\\\envs\\\\pytorch_cu126\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\oriol\\\\anaconda3\\\\envs\\\\pytorch_cu126\\\\Lib\\\\site-packages\\\\Pythonwin']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path \n",
    "from torchvision.transforms import v2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "modulepath = Path.cwd().parent / \"utils\"\n",
    "modulepath = str(modulepath)\n",
    "projectpath = Path.cwd().parent\n",
    "projectpath = str(projectpath)\n",
    "if modulepath not in sys.path:\n",
    "    sys.path.insert(0,str(modulepath))\n",
    "if projectpath not in sys.path:\n",
    "    sys.path.insert(0,str(projectpath))  \n",
    "print(sys.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1c23cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_loaders import create_train_test_dataloaders\n",
    "transform = v2.Compose([v2.RandomCrop(size=(20, 20))])#,v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08b8a80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_basic,test_basic = create_train_test_dataloaders(dataset_name=\"FashionMNIST\",size=0.1)\n",
    "train_augmented,test_augmented = create_train_test_dataloaders(dataset_name=\"FashionMNIST\",transform=transform)\n",
    "img_basic,label_basic = next(iter(train_basic))\n",
    "img_augmented,label_augmented = next(iter(train_augmented))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdc0726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee5cf398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some spaces are good\n",
      "some spaces are good\n"
     ]
    }
   ],
   "source": [
    "train_basic,test_basic = create_train_test_dataloaders(\"some spaces are good\")\n",
    "\n",
    "print(train_basic.dataset.root.split(\"\\\\\")[-1])\n",
    "name = os.path.split(os.path.normpath(train_basic.dataset.root))[-1]\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0b33942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(-0.5), np.float64(19.5), np.float64(19.5), np.float64(-0.5))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(1,2)\n",
    "ax[0].imshow(img_basic[0].permute(1,2,0),cmap=\"gray\")\n",
    "ax[1].imshow(img_augmented[0].permute(1,2,0),cmap=\"gray\")\n",
    "ax[0].axis(False)\n",
    "ax[1].axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfe83b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 28, 28])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_basic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1b73328",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.model_architectures import TinyVGG_1\n",
    "from torchinfo import summary \n",
    "\n",
    "tvgg = TinyVGG_1(1,20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68c2326d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "TinyVGG_1                                [32, 10]                  --\n",
       "├─Sequential: 1-1                        [32, 20, 12, 12]          --\n",
       "│    └─Conv2d: 2-1                       [32, 20, 26, 26]          200\n",
       "│    └─ReLU: 2-2                         [32, 20, 26, 26]          --\n",
       "│    └─Conv2d: 2-3                       [32, 20, 24, 24]          3,620\n",
       "│    └─ReLU: 2-4                         [32, 20, 24, 24]          --\n",
       "│    └─MaxPool2d: 2-5                    [32, 20, 12, 12]          --\n",
       "├─Sequential: 1-2                        [32, 20, 4, 4]            --\n",
       "│    └─Conv2d: 2-6                       [32, 20, 10, 10]          3,620\n",
       "│    └─ReLU: 2-7                         [32, 20, 10, 10]          --\n",
       "│    └─Conv2d: 2-8                       [32, 20, 8, 8]            3,620\n",
       "│    └─ReLU: 2-9                         [32, 20, 8, 8]            --\n",
       "│    └─MaxPool2d: 2-10                   [32, 20, 4, 4]            --\n",
       "├─Sequential: 1-3                        [32, 10]                  --\n",
       "│    └─Flatten: 2-11                     [32, 320]                 --\n",
       "│    └─Linear: 2-12                      [32, 10]                  3,210\n",
       "==========================================================================================\n",
       "Total params: 14,270\n",
       "Trainable params: 14,270\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 90.15\n",
       "==========================================================================================\n",
       "Input size (MB): 0.10\n",
       "Forward/backward pass size (MB): 7.25\n",
       "Params size (MB): 0.06\n",
       "Estimated Total Size (MB): 7.41\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(tvgg,input_size=[32,1,28,28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ceeec08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1039, 0.0984, 0.0970, 0.0983, 0.0958, 0.0985, 0.1001, 0.1020, 0.1042,\n",
       "         0.1018]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvgg.cpu()\n",
    "tvgg.forward(img_basic[0].unsqueeze(dim=0))\n",
    "torch.softmax(tvgg.forward(img_basic[0].unsqueeze(dim=0)),1)\n",
    "\n",
    "#next(tvgg.parameters()).is_cuda #check if model on cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402c7971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Created SummaryWriter, saving to: c:\\Users\\oriol\\GitHub_Repos\\CNN-classification\\experiment_logs\\runs\\TinyVGG_1\\Test_train_function\\1 epochs...\n",
      "[INFO] Created experiment metadata, saving to: c:\\Users\\oriol\\GitHub_Repos\\CNN-classification\\experiment_logs\\runs_metadata\\TinyVGG_1\\Test_train_function\\1 epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3676f1eb9732479eb7e4bae8dfe33e3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils.engine import train\n",
    "from utils.model_architectures import TinyVGG_1\n",
    "from utils.data_loaders import create_train_test_dataloaders\n",
    "from torch import nn\n",
    "from utils.helpers import create_writer\n",
    "from utils.helpers import create_experiment_metadata\n",
    "train_dataloader, test_dataloader = create_train_test_dataloaders(size=0.1) #type: ignore\n",
    "    \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model_0 = TinyVGG_1(input_shape=1,hidden_channels=10,output_shape=10).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(),lr=0.01)\n",
    "#print(f\"Is the model on GPU {next(model_0.parameters()).is_cuda}\")\n",
    "\n",
    "model_name = model_0._get_name()\n",
    "experiment_name = \"Test_train_function\"\n",
    "extra = \"1 epochs\"\n",
    "NUM_EPOCHS = 1\n",
    "\n",
    "writer = create_writer(experiment_name=experiment_name,model_name=model_name,extra=extra)\n",
    "\n",
    "train(model=model_0,train_dataloader=train_dataloader,test_dataloader=test_dataloader,optimizer=optimizer,loss_fn=loss_fn,epochs=NUM_EPOCHS,writer=writer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c01ee294",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_loaders import create_train_test_dataloaders\n",
    "from torchvision import datasets \n",
    "from utils.config import DATA_DIRECTORY\n",
    "mnist = os.path.join(DATA_DIRECTORY,\"FashionMNIST\")\n",
    "train_dataset = datasets.FashionMNIST(root=mnist,train=True,download=False,transform=v2.Compose([v2.ToImage(),v2.ToDtype(torch.float32, scale=True)]))\n",
    "train_basic,test_basic = create_train_test_dataloaders(\"FashionMNIST\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea50e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial len 600, initial type <class 'torchvision.datasets.mnist.FashionMNIST'>\n",
      "470400\n",
      "Final len 60, final type <class 'torchvision.datasets.mnist.FashionMNIST'>\n"
     ]
    }
   ],
   "source": [
    "print(f\"Initial len {len(train_dataset)}, initial type {type(train_dataset)}\")\n",
    "size = 0.1\n",
    "nel = int(len(train_dataset)*size)\n",
    "train_dataset.data = train_dataset.data[0:nel]\n",
    "print(f\"Final len {len(train_dataset)}, final type {type(train_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53b51877",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.config import RUNS_METADATA_DIRECTORY\n",
    "from utils.config import METADATA_FILENAME\n",
    "\n",
    "def retrieve_metadata(model_name:str, experiment_name:str, extra=None):\n",
    "    \"\"\"AAA\"\"\"\n",
    "    if extra:\n",
    "        metadata_path = os.path.join(RUNS_METADATA_DIRECTORY, model_name, \n",
    "                               experiment_name, extra, METADATA_FILENAME)\n",
    "    else:\n",
    "        metadata_path = os.path.join(RUNS_METADATA_DIRECTORY, model_name, \n",
    "                               experiment_name, METADATA_FILENAME)\n",
    "    if os.path.exists(metadata_path):\n",
    "        with open(metadata_path, 'rb') as file:\n",
    "            metadata = pickle.load(file)\n",
    "        return metadata\n",
    "    else:\n",
    "        print(f\"No metadata stored in {metadata_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13aabe7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No metadata stored in c:\\Users\\oriol\\GitHub_Repos\\CNN-classification\\runs_metadata\\TinyVGG_1\\iwhrsgir\\3 epochs SDG\\Metadata.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "meta_dict = retrieve_metadata(model_name=\"TinyVGG_1\", experiment_name=\"iwhrsgir\", extra=\"3 epochs SDG\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec9e12ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'date': '20-08-2025', 'experiment name': 'Test_writer_and_metadata', 'model name': 'TinyVGG_1', 'learning rate': 0.01, 'epochs': 3, 'loss function': 'CrossEntropyLoss', 'optimizer name': 'SGD', 'dataset': 'some spaces are good', 'training dataset size': 60000, 'testing dataset size': 10000, 'batch size': 32, 'optimizer params': {'lr': 0.01, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'fused': None}, 'model params': {'layer_1': Sequential(\n",
      "  (0): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (3): ReLU()\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "), 'layer_2': Sequential(\n",
      "  (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (3): ReLU()\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "), 'layer_3': Sequential(\n",
      "  (0): Flatten(start_dim=1, end_dim=-1)\n",
      "  (1): Linear(in_features=160, out_features=10, bias=True)\n",
      ")}}\n"
     ]
    }
   ],
   "source": [
    "print(meta_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0023c2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oriol\\GitHub_Repos\\CNN-classification\\experiment_logs\\runs\n",
      "c:\\Users\\oriol\\GitHub_Repos\\CNN-classification\\experiment_logs\n",
      "['c:\\\\Users\\\\oriol\\\\GitHub_Repos\\\\CNN-classification\\\\experiment_logs', 'c:\\\\Users\\\\oriol\\\\GitHub_Repos\\\\CNN-classification\\\\experiment_logs\\\\runs', 'c:\\\\Users\\\\oriol\\\\GitHub_Repos\\\\CNN-classification', 'c:\\\\Users\\\\oriol\\\\GitHub_Repos\\\\CNN-classification\\\\utils', 'c:\\\\Users\\\\oriol\\\\anaconda3\\\\envs\\\\pytorch_cu126\\\\python312.zip', 'c:\\\\Users\\\\oriol\\\\anaconda3\\\\envs\\\\pytorch_cu126\\\\DLLs', 'c:\\\\Users\\\\oriol\\\\anaconda3\\\\envs\\\\pytorch_cu126\\\\Lib', 'c:\\\\Users\\\\oriol\\\\anaconda3\\\\envs\\\\pytorch_cu126', '', 'c:\\\\Users\\\\oriol\\\\anaconda3\\\\envs\\\\pytorch_cu126\\\\Lib\\\\site-packages', 'c:\\\\Users\\\\oriol\\\\anaconda3\\\\envs\\\\pytorch_cu126\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\oriol\\\\anaconda3\\\\envs\\\\pytorch_cu126\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\oriol\\\\anaconda3\\\\envs\\\\pytorch_cu126\\\\Lib\\\\site-packages\\\\Pythonwin']\n"
     ]
    }
   ],
   "source": [
    "from utils.config import RUNS_DIRECTORY\n",
    "print(RUNS_DIRECTORY)\n",
    "exlog = os.path.dirname(RUNS_DIRECTORY)\n",
    "print(exlog)\n",
    "if exlog not in sys.path:\n",
    "    sys.path.insert(0,str(exlog))\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daeccfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.engine import train\n",
    "from utils.model_architectures import TinyVGG_1\n",
    "from utils.data_loaders import create_train_test_dataloaders\n",
    "from torch import nn\n",
    "from utils.helpers import create_writer\n",
    "from utils.helpers import create_experiment_metadata\n",
    "train_dataloader, test_dataloader = create_train_test_dataloaders()\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model_0 = TinyVGG_1(input_shape=1,hidden_channels=10,output_shape=10).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743adb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.__getstate__()['defaults']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bae9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0.__getstate__()['_modules']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca7c459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(r\"C:\\Users\\oriol\\GitHub_Repos\\CNN-classification\\runs_metadata\\TinyVGG_1\\Test_writer_and_dict\\2 epochs\\Metadata.pkl\", 'rb') as file:\n",
    "    meta_dict = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30e5a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(meta_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03012040",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9b4818",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrtr.__getstate__()['log_dir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb810f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from utils.config import RUNS_DIRECTORY\n",
    "from utils.helpers import create_writer\n",
    "wrtr = create_writer(model_name=\"None\",experiment_name=\"Test expname extraction\",extra=\"Please\")\n",
    "\n",
    "relpath = os.path.normpath(os.path.relpath(wrtr.__getstate__()['log_dir'],RUNS_DIRECTORY))\n",
    "components = relpath.split(os.sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3d6bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Model name '{components[0]}' and experiment name '{components[1]}'\")\n",
    "type(components[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6306241",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.model_architectures import TinyVGG_1\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model_0 = TinyVGG_1(input_shape=1,hidden_channels=10,output_shape=10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf83a7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.config import RUNS_METADATA_DIRECTORY\n",
    "dictpath = os.path.join(RUNS_METADATA_DIRECTORY,relpath)\n",
    "print(dictpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80220fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from utils.config import RUNS_METADATA_DIRECTORY\n",
    "import pickle\n",
    "metadata_file = os.path.join(RUNS_METADATA_DIRECTORY,\"TinyVGG_1\",\"Test_writer_and_newdict\",\"1 epochs\",\"Metadata.pkl\")\n",
    "with open(metadata_file, 'rb') as f:\n",
    "    resdict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5653dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "resdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04e8cdc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21-08-2025 12:24\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime \n",
    "\n",
    "print(datetime.now().strftime(\"%d-%m-%Y %H:%M\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22a24443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.model_architectures import TinyVGG_1\n",
    "loaded_model = TinyVGG_1(1,10,10)\n",
    "loaded_model.load_state_dict(torch.load(f=r\"C:\\Users\\oriol\\GitHub_Repos\\CNN-classification\\models\\Untrained_TinyVGG_1.pth\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68bff46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_cu126",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
